{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Tensorflow dependencies ###\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "### Some constants ###\n",
    "lr = 1e-4\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "img_shape = (112, 112, 3)\n",
    "latent_dim = 100\n",
    "\n",
    "### Discriminators and Generators weights path ###\n",
    "g_weights_path = \"weights/g.weights.hdf5\" # G : X -> Y\n",
    "f_weights_path = \"weights/f.weights.hdf5\" # F : Y -> X\n",
    "x_weights_path = \"weights/x.weights.hdf5\" # discriminate X and F(Y)\n",
    "y_weights_path = \"weights/y.weights.hdf5\" # discriminate Y and G(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/horse2zebra',\n",
    "                              with_info=True, as_supervised=True)\n",
    "\n",
    "train_horses, train_zebras = dataset['trainA'], dataset['trainB']\n",
    "test_horses, test_zebras = dataset['testA'], dataset['testB'] \n",
    "\n",
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(image, size=[img_shape[0], img_shape[1], 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 112 x 112 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_image_train(image, label):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image, label):\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "train_horses = train_horses.map(\n",
    "    preprocess_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "train_zebras = train_zebras.map(\n",
    "    preprocess_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "test_horses = test_horses.map(\n",
    "    preprocess_image_test, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "test_zebras = test_zebras.map(\n",
    "    preprocess_image_test, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generator G and F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator_G\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 56, 56, 32)        32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 112, 112, 16)      8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 3)       768       \n",
      "=================================================================\n",
      "Total params: 1,952,448\n",
      "Trainable params: 1,951,968\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"Generator_F\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 128)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 64)        131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 56, 56, 32)        32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 112, 112, 16)      8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 3)       768       \n",
      "=================================================================\n",
      "Total params: 1,952,448\n",
      "Trainable params: 1,951,968\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_generator(name):\n",
    "    inputs = Input(shape=(latent_dim,))\n",
    "    \n",
    "    x = Dense(7*7*256, use_bias=False)(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Reshape(target_shape=(7,7,256))(x)\n",
    "    \n",
    "    # Size = 128 x 14 x 14 \n",
    "    x = Conv2DTranspose(128, kernel_size=(4,4), strides=(2,2), padding='same',\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Size = 64 x 28 x 28\n",
    "    x = Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), padding='same',\n",
    "                       use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Size = 32 x 56 x 56\n",
    "    x = Conv2DTranspose(32, kernel_size=(4,4), strides=(2,2), padding='same',\n",
    "                       use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Size = 16 x 112 x 112\n",
    "    x = Conv2DTranspose(16, kernel_size=(4,4), strides=(2,2), padding='same',\n",
    "                       use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Use tanh so that it is [-1, 1]\n",
    "    x = Conv2D(img_shape[-1], kernel_size=(4,4), padding='same', use_bias=False, activation='tanh')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x, name=f'Generator_{name}')\n",
    "    return model\n",
    "\n",
    "G = make_generator('G')\n",
    "F = make_generator('F')\n",
    "\n",
    "print(G.summary())\n",
    "print(F.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator_X\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 112, 112, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 16)        784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        8224      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        32832     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 179,313\n",
      "Trainable params: 179,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"Discriminator_Y\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 112, 112, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 16)        784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        8224      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        32832     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 128)         131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 179,313\n",
      "Trainable params: 179,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_discriminator(name):\n",
    "    inputs = Input(shape=img_shape)\n",
    "    \n",
    "    x = Conv2D(16, kernel_size=(4,4), strides=(2,2), padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(32, kernel_size=(4,4), strides=(2,2), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=(4,4), strides=(2,2), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=(4,4), strides=(2,2), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x, name=f'Discriminator_{name}')\n",
    "    return model\n",
    "\n",
    "X = make_discriminator(\"X\")\n",
    "Y = make_discriminator(\"Y\")\n",
    "\n",
    "print(X.summary())\n",
    "print(Y.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = BinaryCrossentropy(from_logits=True)\n",
    "LAMBDA = 10.0 # scale factor for cycle consistency and identity loss functions\n",
    "\n",
    "def generator_loss(D_fake):\n",
    "    ones = tf.ones_like(D_fake, dtype=tf.float32)\n",
    "    loss = bce(ones, D_fake)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def discriminator_loss(D_real, D_fake):\n",
    "    ones = tf.ones_like(D_real, dtype=tf.float32)\n",
    "    zeros = tf.zeros_like(D_fake, dtype=tf.float32)\n",
    "    \n",
    "    real_loss = bce(ones, D_real)\n",
    "    fake_loss = bce(zeros, D_fake)\n",
    "    loss = real_loss + fake_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def cycle_consistency_loss(cycled_images, real_images):\n",
    "    return LAMBDA * tf.reduce_mean(tf.abs(cycled_images - real_images))\n",
    "\n",
    "def identity_loss(same_images, real_images):\n",
    "    return LAMBDA * 0.5 * tf.reduce_mean(tf.abs(same_images - real_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
